# ------------- MedConsultant v9 (–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–µ—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è) -------------
import io, base64, datetime, json, os, sys, tempfile, uuid, subprocess, glob, re
import streamlit as st
import openai
import fitz  # PyMuPDF
import docx
from docx.shared import Pt, RGBColor
from docx2pdf import convert
from PIL import Image
import pydicom

# ---------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API‚Äë–∫–ª—é—á–∞ ----------
# –ò—â–µ–º —Å–Ω–∞—á–∞–ª–∞ –≤ Streamlit Secrets, –ø–æ—Ç–æ–º ‚Äî –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
openai.api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    st.error("‚ùó –ù–µ –∑–∞–¥–∞–Ω OPENAI_API_KEY. –ó–∞–¥–∞–π—Ç–µ —Å–µ–∫—Ä–µ—Ç –≤ Streamlit Cloud –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    st.stop()

# –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç OpenAI (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å openai.api_key)
openai_client = openai.OpenAI()

# ---------- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ----------
# –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫–æ–Ω–æ–º–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ —Å –ª–∏–º–∏—Ç–∞–º–∏
MODEL       = "gpt-4o-mini"
TEMPERATURE = 0.35
MAX_TOKENS  = 4000
THEME       = RGBColor(0, 102, 204)

# ---------- UI ----------
st.set_page_config("MedConsultant ü©∫", page_icon="ü©∫", layout="wide")
st.title("ü©∫ MedConsultant ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç‚Äë–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç")

st.sidebar.header("üßë‚Äç‚öïÔ∏è –î–∞–Ω–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞")
patient_name = st.sidebar.text_input("–§–ò–û –ø–∞—Ü–∏–µ–Ω—Ç–∞")
patient_age  = st.sidebar.text_input("–í–æ–∑—Ä–∞—Å—Ç")
patient_sex  = st.sidebar.selectbox("–ü–æ–ª", ["", "–ú", "–ñ"])

# ---------- –°–µ—Å—Å–∏—è ----------
if "files" not in st.session_state:
    st.session_state.files = {}

# ---------- –•–µ–ª–ø–µ—Ä: –ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç—ã ----------
def extract_date_from_file(fname: str, data: bytes) -> datetime.date | None:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞—Ç—É —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –∑–∞—Ç–µ–º –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
    patterns = [
        r'(\d{4})[._-](\d{2})[._-](\d{2})', # 2025-07-02
        r'(\d{2})[._-](\d{2})[._-](\d{4})'  # 02-07-2025
    ]
    for pattern in patterns:
        match = re.search(pattern, fname)
        if match:
            try:
                parts = match.groups()
                if len(parts[0]) == 4: year, month, day = map(int, parts)
                else: day, month, year = map(int, parts)
                return datetime.date(year, month, day)
            except ValueError:
                continue

    ext = fname.lower().split('.')[-1]
    try:
        if ext == "pdf":
            with fitz.open(stream=data, filetype="pdf") as doc:
                meta = doc.metadata
                date_str = meta.get('creationDate') or meta.get('modDate')
                if date_str: return datetime.datetime.strptime(date_str[2:10], "%Y%m%d").date()
        elif ext == "docx":
            with io.BytesIO(data) as docx_io:
                doc = docx.Document(docx_io)
                if doc.core_properties.created: return doc.core_properties.created.date()
        elif ext == "dcm":
             with io.BytesIO(data) as dcm_io:
                dcm = pydicom.dcmread(dcm_io)
                date_str = dcm.get("StudyDate") or dcm.get("AcquisitionDate")
                if date_str: return datetime.datetime.strptime(date_str, "%Y%m%d").date()
    except Exception:
        return None
    return None

# ---------- –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ ----------
uploaded = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–µ–¥‚Äë—Ñ–∞–π–ª—ã (PDF, DOCX, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, DICOM‚Ä¶)",
    accept_multiple_files=True
)
if uploaded:
    for f in uploaded:
        if f.name not in st.session_state.files:
            file_data = f.read()
            guessed_date = extract_date_from_file(f.name, file_data) or datetime.date.today()
            st.session_state.files[f.name] = {"data": file_data, "note": "", "date": guessed_date}

# ---------- –§–∞–π–ª—ã, –∑–∞–º–µ—Ç–∫–∏ –∏ –¥–∞—Ç—ã (—Å —Ä—É—á–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π) ----------
if st.session_state.files:
    st.subheader("üìÅ –§–∞–π–ª—ã, –∑–∞–º–µ—Ç–∫–∏ –∏ –¥–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–æ–≤")
    st.info("‚ÑπÔ∏è –î–∞—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –µ—ë –≤—Ä—É—á–Ω—É—é.")

    sorted_files = sorted(st.session_state.files.items(), key=lambda item: item[1]['date'])
    st.session_state.files = dict(sorted_files)

    for fname, meta in st.session_state.files.items():
        with st.expander(f"{fname} (–¥–∞—Ç–∞: {meta['date']:%d.%m.%Y})", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                meta["date"] = st.date_input("–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞", value=meta["date"], key=f"date_{fname}")
            with col2:
                meta["note"] = st.text_area("–ó–∞–º–µ—Ç–∫–∞ –∫ —Ñ–∞–π–ª—É", meta["note"], key=f"note_{fname}")

st.markdown("---")
global_note = st.text_area("üìù –û–±—â–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: —É–¥–µ–ª–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—á–µ–∫...")

# ---------- –•–µ–ª–ø–µ—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ ----------
def process_file(fname: str, data: bytes) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –°–ñ–ê–¢–´–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤."""
    ext = fname.lower().split('.')[-1]
    text_content = ""
    images_base64 = []

    def resize_and_encode(img_bytes: bytes) -> str:
        """–°–∂–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤."""
        try:
            with Image.open(io.BytesIO(img_bytes)) as img:
                img.thumbnail((1024, 1024))
                buf = io.BytesIO()
                # PNG –ª—É—á—à–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞, JPEG - –¥–ª—è —Ñ–æ—Ç–æ. –ò—Å–ø–æ–ª—å–∑—É–µ–º PNG –∫–∞–∫ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π.
                img_format = "PNG"
                if img.mode in ("RGBA", "P"):
                    img = img.convert("RGB")
                img.save(buf, format="JPEG", quality=85) # JPEG –¥–∞–µ—Ç –ª—É—á—à–µ–µ —Å–∂–∞—Ç–∏–µ
                return base64.b64encode(buf.getvalue()).decode('utf-8')
        except Exception:
            # –ï—Å–ª–∏ —Å–∂–∞—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å, –∫–æ–¥–∏—Ä—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return base64.b64encode(img_bytes).decode('utf-8')

    try:
        if ext == "pdf":
            doc = fitz.open(stream=data, filetype="pdf")
            for page in doc:
                text_content += page.get_text() + "\n"
                for img_instance in page.get_images(full=True):
                    xref = img_instance[0]
                    base_image = doc.extract_image(xref)
                    images_base64.append(resize_and_encode(base_image["image"]))
            doc.close()
        elif ext == "docx":
            doc = docx.Document(io.BytesIO(data))
            for para in doc.paragraphs: text_content += para.text + "\n"
            for rel in doc.part.rels.values():
                if "image" in rel.target_ref:
                    images_base64.append(resize_and_encode(rel.target_part.blob))
        elif ext in ("txt", "csv", "md"):
            text_content = data.decode(errors="ignore")
        elif ext == "dcm":
            dcm = pydicom.dcmread(io.BytesIO(data))
            text_content = str(dcm)
            if hasattr(dcm, "pixel_array"):
                img = Image.fromarray(dcm.pixel_array)
                buf = io.BytesIO(); img.save(buf, format="PNG");
                images_base64.append(resize_and_encode(buf.getvalue()))
        elif ext in ("png", "jpg", "jpeg", "tiff", "bmp", "gif"):
            images_base64.append(resize_and_encode(data))
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª {fname}: {e}")
    return {"text": text_content, "images": images_base64}

def integrated_analysis() -> str:
    """–°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏."""
    header = (
        f"–ü–∞—Ü–∏–µ–Ω—Ç: {patient_name or '‚Äî'}, {patient_age or '‚Äî'} –ª–µ—Ç, –ø–æ–ª: {patient_sex or '‚Äî'}.\n"
        "–í—ã ‚Äî –≤–µ–¥—É—â–∏–π –≤—Ä–∞—á‚Äë–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å 20‚Äë–ª–µ—Ç–Ω–∏–º —Å—Ç–∞–∂–µ–º. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –¥–∏–Ω–∞–º–∏–∫—É –ø–æ –¥–∞—Ç–∞–º.\n"
        "–°–§–û–†–ú–ò–†–£–ô–¢–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –°–¢–†–û–ì–û –ü–û –°–¢–†–£–ö–¢–£–†–ï:\n"
        "1) –ü—Ä–æ–≤–µ–¥—ë–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n"
        "2) –ó–∞–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º (—Å –∞–Ω–∞–ª–∏–∑–æ–º –¥–∏–Ω–∞–º–∏–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)\n"
        "3) –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –¥–∏–∞–≥–Ω–æ–∑/–≥–∏–ø–æ—Ç–µ–∑–∞\n"
        "4) –ü–ª–∞–Ω –ª–µ—á–µ–Ω–∏—è (–ø—Ä–µ–ø–∞—Ä–∞—Ç—ã, –¥–æ–∑—ã, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)\n"
        "5) –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏, –¥–æ–ø. –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Å—Ä–æ–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è).\n"
        "–ó–ê–ü–†–ï–©–ï–ù–û: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Ä–∫–µ—Ä—ã, —ç–º–æ–¥–∑–∏, CAPS, —Ñ—Ä–∞–∑—ã ¬´–æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –≤—Ä–∞—á—É¬ª, —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ò–ò."
    )
    messages = [{"role": "system", "content": header}]
    user_content = []

    if global_note.strip():
        user_content.append({"type": "text", "text": f"–û–±—â–∏–µ —É–∫–∞–∑–∞–Ω–∏—è: {global_note.strip()}"})

    for fname, meta in st.session_state.files.items():
        file_date = meta['date'].strftime('%d.%m.%Y')
        file_note = meta['note'].strip()
        file_header = f"=== –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {fname} (–¥–∞—Ç–∞: {file_date}) ===\n"
        if file_note: file_header += f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {file_note}\n"

        processed = process_file(fname, meta["data"])
        file_text = processed['text'].strip()

        if file_text: user_content.append({"type": "text", "text": file_header + file_text[:20000]})
        else: user_content.append({"type": "text", "text": file_header + "(–¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)"})

        for img_b64 in processed['images']:
            user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_b64}"}})

    if not user_content: user_content.append({"type": "text", "text": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."})
    messages.append({"role": "user", "content": user_content})

    resp = openai_client.chat.completions.create(
        model=MODEL, messages=messages, temperature=TEMPERATURE, max_tokens=MAX_TOKENS)
    return resp.choices[0].message.content.strip()

def build_docx(text: str) -> bytes:
    doc = docx.Document()
    p = doc.add_paragraph(); r = p.add_run("–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ")
    r.bold = True; r.font.size = Pt(22); r.font.color.rgb = THEME
    doc.add_paragraph(f"{datetime.datetime.now():%d.%m.%Y %H:%M}")
    doc.add_paragraph(f"–ü–∞—Ü–∏–µ–Ω—Ç: {patient_name or '‚Äî'}, {patient_age or '‚Äî'} –ª–µ—Ç, –ø–æ–ª: {patient_sex or '‚Äî'}")
    doc.add_paragraph().add_run("‚ïê" * 40)
    for line in text.splitlines(): doc.add_paragraph(line.strip())
    buf = io.BytesIO(); doc.save(buf)
    return buf.getvalue()

def docx_to_pdf(docx_bytes: bytes) -> bytes | None:
    try:
        with tempfile.TemporaryDirectory() as tmp:
            docx_path = os.path.join(tmp, f"{uuid.uuid4()}.docx")
            with open(docx_path, "wb") as f: f.write(docx_bytes)
            convert(docx_path, tmp)
            pdf_paths = glob.glob(os.path.join(tmp, "*.pdf"))
            if not pdf_paths: raise FileNotFoundError("PDF –Ω–µ —Å–æ–∑–¥–∞–Ω.")
            return open(pdf_paths[0], "rb").read()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ PDF: {e}")
        return None

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ ----------
def generate_report():
    if not st.session_state.files:
        st.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return

    with st.spinner("–ò–ò –ø—Ä–æ–≤–æ–¥–∏—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã..."):
        result_text = integrated_analysis()

    st.success("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    st.markdown("### –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç:")
    st.text_area("–¢–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞", result_text, height=600, key="result_text_area")

    docx_bytes = build_docx(result_text)
    st.session_state.docx_bytes = docx_bytes
    pdf_bytes = docx_to_pdf(docx_bytes)
    if pdf_bytes: st.session_state.pdf_bytes = pdf_bytes


st.markdown("---")
if st.button("üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç", type="primary"):
    generate_report()

if "docx_bytes" in st.session_state:
    col1, col2 = st.columns(2)
    with col1:
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å DOCX", st.session_state.docx_bytes,
            f"MedReport_{patient_name or 'P'}.docx",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    if "pdf_bytes" in st.session_state:
        with col2:
            st.download_button(
                "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å PDF", st.session_state.pdf_bytes,
                f"MedReport_{patient_name or 'P'}.pdf", "application/pdf"
            )